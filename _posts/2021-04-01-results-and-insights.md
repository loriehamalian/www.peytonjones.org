---
title: "Results and Insights from Diagnostic Questions: The NeurIPS 2020 Education Challenge"
excerpt: "Zichao Wang, Angus Lamb, Evgeny Saveliev, Yordan Zaykov, Pashmina Cameron, Jose Miguel Hernandez-Lobato, Richard E. Turner, Richard G. Baraniuk, Simon Peyton Jones, Craig Barton, Simon Woodhead, Cheng Zhang <br><br> Published in <em>NeurIPS Competition</em>
<br><br>
To appear in PMLR proceeding of NeurIPS competition <br><br>
[View PDF](../assets/pdfs/neurips-2020-preprint.pdf){: .btn .btn--info ..btn--large}
[Download BibTex](../assets/bibtex/results-insights-neurips-2020.bib){: .btn .btn--info ..btn--large}"
permalink: /results-and-insights/
header:
  overlay_image: /assets/images/spj-stock-header.jpg
  overlay_filter: 0.5
tags:
- publication
---

# Abstract
This competition concerns educational diagnostic questions, which are pedagogically effective, multiple-choice questions (MCQs) whose distractors embody misconceptions. With a large and ever-increasing number of such questions, it becomes overwhelming for teachers to know which questions are the best ones to use for their students. We thus seek to answer the following question: how can we use data on hundreds of millions of answers to MCQs to drive automatic personalized learning in large-scale learning scenarios where manual personalization is infeasible? Success in using MCQ data at scale helps build more intelligent, personalized learning platforms that ultimately improve the quality of education en masse. To this end, we introduce a new, large-scale, real-world dataset and formulate 4 data mining tasks on MCQs that mimic real learning scenarios and target various aspects of the above question in a competition setting at NeurIPS 2020. We report on our NeurIPS competition in which nearly 400 teams submitted approximately 4000 submissions, with encouragingly diverse and effective approaches to each of our tasks.
